{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b61ff5-1ca4-4bf3-b6e0-6bac8be873f1",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "770e9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ef372",
   "metadata": {},
   "source": [
    "# 1. Text Classification\n",
    "\n",
    "\n",
    "### It is highly recommended that you complete this project using Keras1 and Python.\n",
    "### (a) In this problem, we are trying to build a classifier to analyze the sentiment of reviews. \n",
    "### You are provided with text data in two folders: one folder involves positive reviews, and one folder involves negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b367f679",
   "metadata": {},
   "source": [
    "# (b) Data Exploration and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc0eca",
   "metadata": {},
   "source": [
    "### i. You can use binary encoding for the sentiments , i.e y = 1 for positive sentiments and y = −1 for negative sentiments.\n",
    "\n",
    "### ii. The data are pretty clean. Remove the punctuation and numbers from the data.\n",
    "\n",
    "### iii. The name of each text file starts with cv number. Use text files 0-699 in each class for training and 700-999 for testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d0403-da35-47ae-be06-851677dab1e4",
   "metadata": {},
   "source": [
    "The function below takes in the file path and the encoding value.\n",
    "The files in the directory (pos or neg) are listed and iterated through and separated into test and train based on the three digit number following \"cv\" in the file name. The data is then cleaned of punctuation, and numbers. The data is then zipped together with its encoding value and the train and test with encoding (labeling) is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aabf12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_split_encode_files(filepath,encode):\n",
    "    files = os.listdir(filepath)\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "    for file in files:\n",
    "            file_number = int(file[2:5]) \n",
    "            if 0 <= file_number < 700:\n",
    "                train_files.append(file)\n",
    "            elif 700 <= file_number <= 999:\n",
    "                test_files.append(file)\n",
    "\n",
    "    train_data = [open(os.path.join(filepath, file), 'r', encoding='utf-8').read() for file in train_files]\n",
    "    train_data = [re.sub(r'\\d+', '', word) for word in train_data]\n",
    "    train_data = [re.sub(r'[^\\w\\s]', ' ', word) for word in train_data]\n",
    "    train_data = [word.lower() for word in train_data]\n",
    "    train_data = [word.replace('\\n', ' ') for word in train_data]\n",
    "    train_data = [word.replace(\"_\", \" \") for word in train_data]\n",
    "    train_data = [word.replace(\"-\", \" \") for word in train_data]\n",
    "    train_labeled = [(text, encode) for text in train_data]\n",
    "\n",
    "    test_data = [open(os.path.join(filepath, file), 'r', encoding='utf-8').read() for file in test_files]\n",
    "    test_data = [re.sub(r'\\d+', '', word) for word in test_data]\n",
    "    test_data = [re.sub(r'[^\\w\\s]', ' ', word) for word in test_data]\n",
    "    test_data = [word.lower() for word in test_data]\n",
    "    test_data = [word.replace('\\n', ' ') for word in test_data]\n",
    "    test_data = [word.replace(\"_\", \" \") for word in test_data]\n",
    "    test_data = [word.replace(\"-\", \" \") for word in test_data]\n",
    "    test_labeled = [(text, encode) for text in test_data]\n",
    "    \n",
    "    return train_labeled, test_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dadf28-243d-4031-a2a2-7cd33805c6dd",
   "metadata": {},
   "source": [
    "After much trial and error with using -1 and 1, I ultimately altered the encoding to 0 and 1 to be compatible with the sigmoid activation function and binary cross entropy loss function. I had previusly attempted to use tanh for the activation function, however after trying binary cross entropy, hinge, etc as the loss function, I could not determine a valid loss function to use. Binary cross entropy expects the output to be a binary 0 and 1 so i thought it made the most sense to change the encoding for valid results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd40cdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "neg_train,neg_test = clean_split_encode_files(\"../Data/neg\",0)\n",
    "pos_train,pos_test = clean_split_encode_files(\"../Data/pos\",1)\n",
    "train_data = neg_train + pos_train\n",
    "test_data = neg_test + pos_test\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1d0fe",
   "metadata": {},
   "source": [
    "### iv. Count the number of unique words in the whole dataset (train + test) and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ba3d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Word Count: 38916 words\n"
     ]
    }
   ],
   "source": [
    "total_data = train_data + test_data\n",
    "unique_words = set()\n",
    "for text, label in total_data:\n",
    "    words = text.lower().split()\n",
    "    unique_words.update(words) \n",
    "print(f\"Unique Word Count: {len(unique_words)} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1927d-94a2-467c-8225-9fa42f96f577",
   "metadata": {},
   "source": [
    "There are 38,916 unique words in the total dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a5711",
   "metadata": {},
   "source": [
    "### v. Calculate the average review length and the standard deviation of review lengths. Report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a8604c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average review length: 665.61 words\n",
      "Standard deviation review length: 293.65 words\n"
     ]
    }
   ],
   "source": [
    "review_lengths = [len(review.split()) for review, sentiment in total_data]\n",
    "average_review = np.mean(review_lengths)\n",
    "std_review = np.std(review_lengths)\n",
    "print(f\"Average review length: {round(average_review,2)} words\")\n",
    "print(f\"Standard deviation review length: {round(std_review,2)} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aadb94-c785-472d-b1a2-35f1f052627e",
   "metadata": {},
   "source": [
    "On average, a review length is 665.61 words and the standard deviation of review length is 293.65 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579ff5db",
   "metadata": {},
   "source": [
    "### vi. Plot the histogram of review lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "276dda7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(review_lengths, bins=15, color='red', edgecolor='black') \n",
    "plt.title('Histogram of Review Lengths')\n",
    "plt.xlabel('Review Length (number of words)')\n",
    "plt.ylabel('Occurences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54baa66d-2a91-4b09-99ea-e9ea6f00ea27",
   "metadata": {},
   "source": [
    "From the histogram, we can see a lot of occurences around 500 to 600 words which is relatively close to the average. The review lengths appear to follow a normal distribution. This is because the shape of the histogram follows a bell curve with possibly a small amount of right skewness as there appears to be more occurences of data concentrated on the left side of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d846f9-2c11-4691-ba36-d92b27b2de30",
   "metadata": {},
   "source": [
    "### viii. Select a review length L that 70% of the reviews have a length below it. If you feel more adventurous, set the threshold to 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9baa3e4-bdde-4c30-a33c-cb59361d6475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "759.3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile70_review = np.percentile(review_lengths,70)\n",
    "percentile70_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663358ae-e5ad-4899-9eba-3add2ac78217",
   "metadata": {},
   "source": [
    "The 70th percentile review length is 759.3 (rounded to 760) which means that roughly 70% of review lengths are under 760 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76101df7-1540-4bbc-a1be-4afcccdfd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 760"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c99be3f-118b-4c34-b4fc-7b65077487f8",
   "metadata": {},
   "source": [
    "### vii. To represent each text (= data point), there are many ways. In NLP/Deep Learning terminology, this task is called tokenization. It is common to rep- resent text using popularity/ rank of words in text. The most common word in the text will be represented as 1, the second most common word will be represented as 2, etc. Tokenize each text document using this method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b99e12-121a-40b6-9631-7fdf67f3ff88",
   "metadata": {},
   "source": [
    "### ix. Truncate reviews longer than L words and zero-pad reviews shorter than L so that all texts (= data points) are of length L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1d1d664-371b-46d5-ab0e-d8be6fc88028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('108 108 108 10 25 601 140 5 275 70 5431 44 794 1 5630 4 1 6396 55 10 7711 166 22 156 13 30 97 43 22 2 22 2 22 2 138 906 22 297 1 215 75 61 119 8685 3285 8 13021 13 1085 1657 816 10795 500 28 904 5877 1 13022 1458 25344 4584 39 6 93 60 25 75 310 5 1294 59 569 2 181 32 15 26 10 6 1 185 10 9 33 574 338 23 5432 16 1946 1329 3428 28 73 33 1889 13 1 469 83 287 15 26 30 67 110 24 411 5 972 124 129 25 4 14 1513 100 18 283 2 26 2 6693 149 13 108 701 12 2 702 394 15 26 6397 42 1189 220 2385 15 26 1240 2 19 39 21 686 4 9 10 21 41 108 35 21 182 176 41 17 203 657 9 2 3 406 10 6 90 7322 189 31 1 450 693 17 1134 10 17 94 2 848 2 2205 20 109 954 29 60 21 1 85 1 693 179 402 2916 19 1 82 107 30 84 1271 2 134 10795 201 264 111 4458 23 2 219 7 2 3208 6694 17 94 757 62 365 163 1 578 10 33 1917 9 92 74 1947 368 3 11 347 11 1 82 107 6 102 56 690 5 2 308 6398 107 5 24 1676 11 17 2792 124 15 26 16731 23 53 97 1126 1065 9 33 17 179 3663 43 1 1127 42 4 238 450 315 9 10796 44 210 368 7 1 16 12 1 727 4 1 701 222 1 316 4 1 16 9 714 22 34 1280 105 55 1 450 94 110 71 1947 41 46 6 15 26 43 30 976 40 9 93 1658 1604 125 227 15 38 304 1135 1827 23 1407 19946 11817 4459 3 37 354 131 5 254 5 451 5 3025 2 19947 7 1 291 1594 233 39 35 76 1619 5 192 640 724 11 70 5 51 19948 11 237 363 9 277 473 22 13 51 3664 108 1890 2425 3 1 26 5232 97 51 423 679 13 1 559 11 1 8686 4 1871 74 5 79 274 31 134 14579 5 8687 3 1677 5 894 5058 293 2177 79 20 2 10797 9300 39 21 2 323 4 75 2917 2276 1217 7 13 63 3588 19 1 1871 6 1 25 10 275 70 5431 44 15 184 31 2 1918 7712 39 6 186 3286 125 75 61 1 844 1458 3141 12 134 25345 10 8685 3285 669 5 34 1 280 6 41 1126 108 10 9 1295 6 176 7 686 421 3428 36 16732 1217 7 25346 4 1948 106 5631 3 109 38 64 907 15 6 109 1917 3 9 7713 105 42 144 17 976 30 12 435 40 10 97 54 30 131 367 3428 94 1281 5 5059 11 118 134 651 11 546 58 1 280 406 18 332 9 69 87 1 26 250 5060 17 114 22 120 19 38 1 134 651 7 1 139 714 22 24 411 5 4737 1 108 701 3 59 559 211 19 1 6992 280 227 272 78 12 1 6992 727 4 274 363 7 15 26 17 178 152 265 123 424 153 61 3285 1620 12 15 3142 7 185 39 6 25 107 1 25 7 48 35 21 7 2 587 1809 5 254 5 87 51 13023 222 48 17 93 94 5 496 55 3285 49 14 11818 94 53 3589 641 364 13024 817 5 1 1136 3 701 1 291 7 15 26 17 182 297 44 5 1872 109 560 1190 5 84 55 9 33 1722 39 33 121 2 3287 4 1479 25347 31 1 16733 104 56 34 1 196 82 1949 443 362 25348 28 191 2240 1 2918 4 1 1135 15 36 297 5 24 1 25349 285 219 10 36 195 239 2079 7 1038 4 2 758 259 418 1330 14 211 116 22 193 477 5 242 44 13 14 307 55 30 34 71 797 272 44 5 15 215 15 1705 22 676 30 3285 8 6695 4 78 14580 606 73 34 1 4186 4 111 1014 1657 5 131 272 12 51 75 13025 11817 4459 200 1407 1 1097 4 1 1135 3 62 676 125 50 33 196 13 37 4460 2541 29 37 1408 3 539 50 92 2241 1 3848 2 148 252 3 2452 37 658 1408 1330 37 1361 6 182 11 816 11 37 4738 1948 9 2 6993 26 41 17 203 701 2 6993 464 104 56 34 759 6696 13026 4061 1891 7 2 1014 318 165 11 6697 25 4 1 75 1135 946 15 227 272 12 1 316 4 1 2917 835 7 1 26 3285 5233 2 2581 13026 12 2 13027 5 481 13 3 28 607 36 62 211 619 32 38 19 37 3751 117 21 1 947 2032 4 38 277 8685 144 6 1 64 5 74 7323 3 1394 7 52 78 1873 3752 20 1 44 410 50 92 34 2 247 19949 107 17 560 40 17 203 701 2 464 7 2 1828 2426 19 1948 17 249 1207 9 1 60 310 10 17 179 1620 5 972 124 15 1563 26 33 5 1208 2 181 32 4061 1891 1621 3 197 10 33 2 845 2032 17 275 70 1178 77 570 4 109 88 20 15 3142 1 60 184 10 17 54 187 43 15 26 6 10 30 164 884 223 31 9 1529 4 226 30 260 5 289 63 43 1160 23 2122 10 59 2 14581 4899 1346 16 1946 40 1329 3428 36 4062 44 32 217 233 7 14 88 90 3 55 30 21 835 4 5878 9 42 13 1 1020 235 8 30 21 153 89 53 25350 3751 4061 1891 1191 89 1 3209 15 6 2 26 10 164 24 6399 32 38 4585 27 59 153 365 230 24 5 3362 430 6994 5 238 2 2242 20 1 809 4 794 1 5630 4 1 6396 8164 15 26 6 552 16734 5 170 1079 263 4461 12 1829 8688',\n",
       "  0),\n",
       " ('8165 6 29 2 26 9 6 2 755 180 16735 996 6120 3 2 80 108 25 32 10 15 26 6 41 547 3 919 10 9 8 2582 5 174 10 52 254 7714 179 997 15 1 1218 642 3 59 45 1380 6 1 185 10 15 6 2 476 26 17 203 277 414 21 1 1459 155 4 15 26 19 60 422 391 1 731 4 484 171 24 411 5 9979 9 9 6 1 68 4 2 3508 2 25351 385 8165 2314 23 25352 312 224 36 71 614 223 5 44 2793 48 56 120 782 298 4 226 56 54 1066 1 1950 618 5 214 75 3 35 179 703 5 1 908 4 2386 5 8166 1 2425 12 51 6698 19 9 204 42 977 179 9 8 182 176 7 2 85 1 60 2583 229 3 1742 72 347 565 2 99 304 385 14582 5061 25353 201 28 1031 8165 20 1 137 4 2 2542 3 2148 2243 57 14582 6 2 810 1232 3 1 16 227 89 20 2 845 19950 5 202 37 99 4187 3 1 101 2427 5 9 46 6 1 215 4 15 406 50 6 25 4 1 1179 8 6699 3 35 895 5 202 37 20 418 5 11819 37 49 136 56 104 690 5 2 845 1253 6121 3 2387 7 20 129 201 715 385 2149 13028 25354 28 6 1272 86 14 6995 311 6 3288 18 795 1 783 3 652 14582 5061 19 18 2315 580 7 2 3079 269 86 18 33 1480 20 1 7715 1636 12 2 2033 20 19951 248 22 84 10 25 502 439 5 9980 3 6 5062 2008 11 8165 5063 27 25355 8167 102 5 57 3 2970 57 55 15 94 29 71 7716 547 478 1 68 542 1282 47 14582 283 8165 5 2149 28 104 522 44 1192 1 16736 4 2 1273 14583 5879 47 2149 8 4586 1 206 16736 1316 3 795 14 2687 5 2149 3 8165 4 226 39 236 24 2 798 19 59 15 798 25356 11 25357 166 22 10 320 18 110 4188 14 503 49 276 1546 3 4 226 18 36 1 1001 4462 5880 5064 8165 19 15 6 53 41 794 547 3 9301 56 21 987 77 2584 1830 4 1 68 9 8 244 5 405 638 1 891 19952 3 13029 5 1 26 6 6400 86 9 6 2 224 16 49 55 1 1784 8 21 53 15 10798 3 547 32 252 8165 6 6401 5 241 1161 9302 9 25 199 3 29 1 5632 4587 19 9 8 53 41 6402 511 2080 919 1564 2739 3 53 1678 108 9 171 2316 414 9 389 4739 105 84 73 1679',\n",
       "  0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization of total data set combined\n",
    "reviews = [text for text, sentiment in total_data]\n",
    "sentiments = [sentiment for text, sentiment in total_data]\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "\n",
    "ranks = tokenizer.texts_to_sequences(reviews)\n",
    "ranked_data = [(\" \".join(str(item) for item in rank), sentiment) for rank, sentiment in zip(ranks, sentiments)]\n",
    "ranked_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99f33d97-9927-45bb-a620-c72f4043aed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  108,   108,   108, ...,    51,    75, 11874],\n",
       "       [ 6461,     6,    29, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews = [text for text,sentiment in train_data]\n",
    "train_sentiments = [sentiment for text, sentiment in train_data]\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_reviews)\n",
    "\n",
    "train_ranks = tokenizer.texts_to_sequences(train_reviews)\n",
    "train_ranked_data = [(\" \".join(str(item) for item in rank), sentiment) for rank, sentiment in zip(train_ranks, train_sentiments)]\n",
    "\n",
    "# L defined earlier with 70th percentile\n",
    "x_train = pad_sequences(train_ranks,maxlen=L, padding='post',truncating='post')\n",
    "y_train = [sentiment for text, sentiment in train_ranked_data]\n",
    "\n",
    "# convert sentiments to np array for compatibility\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22221fa4-4274-4eb7-8975-7b35db9b1e6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 155,   22,   10, ...,    0,    0,    0],\n",
       "       [2537, 3464, 7006, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization and padding performed on train and test separately\n",
    "test_reviews = [text for text,sentiment in test_data]\n",
    "test_sentiments = [sentiment for text, sentiment in test_data]\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(test_reviews)\n",
    "\n",
    "test_ranks = tokenizer.texts_to_sequences(test_reviews)\n",
    "test_ranked_data = [(\" \".join(str(item) for item in rank),sentiment) for rank, sentiment in zip(test_ranks,test_sentiments)]\n",
    "x_test = pad_sequences(test_ranks, maxlen=L, padding='post',truncating='post')\n",
    "y_test = [sentiment for text, sentiment in test_ranked_data]\n",
    "\n",
    "# convert the sentiments to array\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "x_test[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04524ec8-73ca-4e57-9d7d-479d66a6b5bb",
   "metadata": {},
   "source": [
    "# (c) Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd1c691-4a08-48e9-850d-418c0f6ee15a",
   "metadata": {},
   "source": [
    "### i. One can use tokenized text as inputs to a deep neural network. However, a re- cent breakthrough in NLP suggests that more sophisticated representations of text yield better results. These sophisticated representations are called word embeddings. “Word embedding is a term used for representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vectorspace are expected to be similar in meaning.”. Most deep learning modules (including Keras) provide a convenient way to convert positive integer rep- resentations of words into a word embedding by an “Embedding layer.” The layer accepts arguments that define the mapping of words into embeddings, including the maximum number of expected words also called the vocabulary size (e.g. the largest integer value). The layer also allows you to specify the dimension for each word vector, called the “output dimension.” We would like to use a word embedding layer for this project. Assume that we are interested in the top 5,000 words. This means that in each integer sequence that represents each document, we set to zero those integers that represent words that are not among the top 5,000 words in the document. If you feel more adventurous, use all the words that appear in this corpus. Choose the length of the embedding vector for each word to be 32. Hence, each document is represented as a 32 × L matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dc1d44-eef3-4a6c-9b22-92b8a7f4c4ca",
   "metadata": {},
   "source": [
    "### ii. Flatten the matrix of ach document to a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892c172d-9400-406c-8276-dc9eb8635812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 13:55:48.437357: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-05-07 13:55:48.437377: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-05-07 13:55:48.437382: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-05-07 13:55:48.437408: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-07 13:55:48.437420: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-05-07 13:55:48.762746: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 22ms/step - loss: 0.6848 - accuracy: 0.5683 - val_loss: 0.7500 - val_accuracy: 0.2286\n",
      "Epoch 2/2\n",
      " 4/40 [==>...........................] - ETA: 0s - loss: 0.6042 - accuracy: 0.8672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 13:55:49.735027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 18ms/step - loss: 0.5884 - accuracy: 0.8246 - val_loss: 0.7867 - val_accuracy: 0.3071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1561ba4c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_model = Sequential()\n",
    "embedded_model.add(Embedding(input_dim=5000,output_dim=32,input_length=L))\n",
    "embedded_model.add(Flatten())\n",
    "embedded_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "embedded_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "# perform validation on small subset of train data\n",
    "embedded_model.fit(x_train, y_train,epochs=2,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf67061-992a-486c-bc35-efd162fd52f9",
   "metadata": {},
   "source": [
    "# (d) Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc5c52-2ccc-4667-a491-3ce22b274fa1",
   "metadata": {},
   "source": [
    "### i. Train a MLP with three (dense) hidden layers each of which has 50 ReLUs and one output layer with a single sigmoid neuron. Use a dropout rate of 20% for the first layer and 50% for the other layers. Use ADAM optimizer and binary cross entropy loss (which is equivalent to having a softmax in the output). To avoid overfitting, just set the number of epochs as 2. Use a batch size of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0d78b12-eeea-47d2-92dc-5edc20d4c2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 15:46:06.980435: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - ETA: 0s - loss: 0.7221 - accuracy: 0.5206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 15:46:12.098960: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 6s 37ms/step - loss: 0.7221 - accuracy: 0.5206 - val_loss: 0.7037 - val_accuracy: 0.4643\n",
      "Epoch 2/2\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.5739 - accuracy: 0.6817 - val_loss: 0.9124 - val_accuracy: 0.2786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x39114c490>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = Sequential()\n",
    "mlp_model.add(Embedding(input_dim=5000,output_dim=32, input_length=L))\n",
    "mlp_model.add(Flatten()) # dropout of 0.2 for first layer and 0.5 for other layers\n",
    "mlp_model.add(Dense(50, activation='relu'))\n",
    "mlp_model.add(Dropout(0.2))\n",
    "mlp_model.add(Dense(50, activation='relu'))\n",
    "mlp_model.add(Dropout(0.5))\n",
    "mlp_model.add(Dense(50, activation='relu'))\n",
    "mlp_model.add(Dropout(0.5))\n",
    "mlp_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "mlp_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "mlp_model.fit(x_train,y_train, epochs=2, batch_size=10,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb840a0e-0cd0-4638-be6d-bcdf14a560aa",
   "metadata": {},
   "source": [
    "### ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7233d827-df0e-4ef0-8d4b-8819a84df78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 2ms/step\n",
      "Train Accuracy: 0.824\n",
      "19/19 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 15:46:18.479963: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.528\n"
     ]
    }
   ],
   "source": [
    "# a threshold of 0.5 was used to convert predictions\n",
    "train_predictions = mlp_model.predict(x_train)\n",
    "binary_train_predictions = (train_predictions >= 0.5).astype(int)\n",
    "train_accuracy = accuracy_score(y_train, binary_train_predictions)\n",
    "print(f\"Train Accuracy: {round(train_accuracy,3)}\")\n",
    "\n",
    "test_predictions = mlp_model.predict(x_test)\n",
    "binary_test_predictions = (test_predictions >= 0.5).astype(int)\n",
    "test_accuracy = accuracy_score(y_test, binary_test_predictions)\n",
    "print(f\"Test Accuracy: {round(test_accuracy,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37c7aba-7617-4bdb-8d32-25588e94a64a",
   "metadata": {},
   "source": [
    "The Multi Layer Perceptron model achieved a relatively high train accuracy of 0.824 but a much lower test accuracy of 0.528. This model was run several times and produced a train accuracy in the range of 0.65 to 0.88. The test accuracy range is consistently around 0.50 to 0.60. In one run, the train accuracy reached as high as 0.889, however the test accuracy for this run was around 0.47 which indicates some degree of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af632cc-4178-4405-b4e9-a7cf824f2108",
   "metadata": {},
   "source": [
    "# (e) One-Dimensional Convolutional Neural Network:\n",
    "\n",
    "#### Although CNNs are mainly used for image data, they can also be applied to text data, as text also has adjacency information. Keras supports one-dimensional convolutions and pooling by the Conv1D and MaxPooling1D classes respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a521f-52f0-4d00-a83a-21b84bc3429e",
   "metadata": {},
   "source": [
    "### i. After the embedding layer, insert a Conv1D layer. This convolutional layer has 32 feature maps , and each of the 32 kernels has size 3, i.e. reads embedded word representations 3 vector elements of the word embedding at a time. The convolutional layer is followed by a 1D max pooling layer with a length and stride of 2 that halves the size of the feature maps from the convolutional layer. The rest of the network is the same as the neural network above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bccead6-8b2f-4efa-a78e-f431fc918eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one embedded layer, a Conv1D layer \n",
    "# stride defaults to same value as pool_size\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(input_dim=5000,output_dim=32, input_length=L))\n",
    "cnn_model.add(Conv1D(filters=32,kernel_size=3, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dropout(0.2))\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39a9c3e8-8aeb-4ded-b0bf-63446b435d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 13:55:56.335385: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 4s 25ms/step - loss: 0.7458 - accuracy: 0.5262 - val_loss: 0.8233 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "  1/126 [..............................] - ETA: 3s - loss: 0.6857 - accuracy: 0.4000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 13:55:59.525276: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 3s 22ms/step - loss: 0.6865 - accuracy: 0.5627 - val_loss: 0.5235 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x175f6c460>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform validation done on small subset of train data\n",
    "cnn_model.fit(x_train,y_train,epochs=2, batch_size=10,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cb420-aeb5-4d84-9230-de40052fb29a",
   "metadata": {},
   "source": [
    "### ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e6600cf-a85a-40fb-a435-45375a190403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 2ms/step\n",
      "Train Accuracy: 0.502\n",
      " 1/19 [>.............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 13:56:02.470715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step\n",
      "Test Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "train_predictions = cnn_model.predict(x_train)\n",
    "binary_train_predictions = (train_predictions >= 0.5).astype(int)\n",
    "train_accuracy = accuracy_score(y_train, binary_train_predictions)\n",
    "print(f\"Train Accuracy: {round(train_accuracy,3)}\")\n",
    "\n",
    "test_predictions = cnn_model.predict(x_test)\n",
    "binary_test_predictions = (test_predictions >= 0.5).astype(int)\n",
    "test_accuracy = accuracy_score(y_test, binary_test_predictions)\n",
    "print(f'Test Accuracy: {round(test_accuracy,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e808bc3-d50a-41fd-8a11-1d27a1ccac52",
   "metadata": {},
   "source": [
    "The train and test accuracy of the 1D CNN model is consistently about 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa901b-eae9-49ee-a7e3-a5b91a412cbb",
   "metadata": {},
   "source": [
    "# (f) Long Short-Term Memory Recurrent Neural Network:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be346e80-2430-487c-b9bf-f969e6fd2a50",
   "metadata": {},
   "source": [
    "### i. Each word is represented to LSTM as a vector of 32 elements and the LSTM is followed by a dense layer of 256 ReLUs. Use a dropout rate of 0.2 for both LSTM and the dense layer. Train the model using 10-50 epochs and batch size of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "824afa99-c878-4185-b734-04cd51660cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense layer of 256 ReLUs\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=5000,output_dim=32,input_length=760))\n",
    "lstm_model.add(LSTM(256))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(256,activation='relu'))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02f2d3a5-8e24-4b82-bb26-b3bf9f06fc53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 13:56:03.235394: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-05-07 13:56:03.342527: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/126 [..............................] - ETA: 2:02 - loss: 0.6926 - accuracy: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 13:56:03.636551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.5571"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 13:56:11.027262: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-05-07 13:56:11.074636: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 9s 62ms/step - loss: 0.6866 - accuracy: 0.5571 - val_loss: 0.7769 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.6746 - accuracy: 0.6127 - val_loss: 0.8742 - val_accuracy: 0.2214\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.6171 - accuracy: 0.6611 - val_loss: 0.8831 - val_accuracy: 0.1571\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.5986 - accuracy: 0.6730 - val_loss: 0.7393 - val_accuracy: 0.8357\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.5908 - accuracy: 0.6429 - val_loss: 1.7927 - val_accuracy: 0.2214\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.5362 - accuracy: 0.6865 - val_loss: 1.1538 - val_accuracy: 0.1286\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.6000 - accuracy: 0.6563 - val_loss: 1.0061 - val_accuracy: 0.1571\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4911 - accuracy: 0.7095 - val_loss: 1.3375 - val_accuracy: 0.1429\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4876 - accuracy: 0.6857 - val_loss: 1.1469 - val_accuracy: 0.1643\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4855 - accuracy: 0.6897 - val_loss: 1.2080 - val_accuracy: 0.1571\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4914 - accuracy: 0.7040 - val_loss: 0.9118 - val_accuracy: 0.2143\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.5213 - accuracy: 0.6603 - val_loss: 0.9755 - val_accuracy: 0.1714\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4853 - accuracy: 0.7095 - val_loss: 1.0168 - val_accuracy: 0.1929\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.5737 - accuracy: 0.6444 - val_loss: 1.1092 - val_accuracy: 0.1571\n",
      "Epoch 15/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4837 - accuracy: 0.7111 - val_loss: 0.9778 - val_accuracy: 0.2214\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4824 - accuracy: 0.7119 - val_loss: 1.1253 - val_accuracy: 0.1429\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4788 - accuracy: 0.7111 - val_loss: 1.2434 - val_accuracy: 0.1357\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4816 - accuracy: 0.7008 - val_loss: 0.7733 - val_accuracy: 0.2429\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4824 - accuracy: 0.7087 - val_loss: 0.9534 - val_accuracy: 0.1786\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4814 - accuracy: 0.7056 - val_loss: 1.1724 - val_accuracy: 0.1643\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4839 - accuracy: 0.6968 - val_loss: 0.7684 - val_accuracy: 0.8571\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4847 - accuracy: 0.6968 - val_loss: 1.1530 - val_accuracy: 0.1929\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4825 - accuracy: 0.7103 - val_loss: 1.0586 - val_accuracy: 0.1857\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4749 - accuracy: 0.7111 - val_loss: 1.0708 - val_accuracy: 0.1643\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4821 - accuracy: 0.7095 - val_loss: 1.3072 - val_accuracy: 0.1429\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4788 - accuracy: 0.7119 - val_loss: 1.2487 - val_accuracy: 0.1429\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4797 - accuracy: 0.7119 - val_loss: 1.3510 - val_accuracy: 0.1214\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4799 - accuracy: 0.7032 - val_loss: 1.6607 - val_accuracy: 0.1143\n",
      "Epoch 29/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4778 - accuracy: 0.7071 - val_loss: 1.4888 - val_accuracy: 0.1214\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4921 - accuracy: 0.6873 - val_loss: 1.0080 - val_accuracy: 0.1571\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4812 - accuracy: 0.7135 - val_loss: 1.0215 - val_accuracy: 0.1857\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.5190 - accuracy: 0.6944 - val_loss: 1.3305 - val_accuracy: 0.1786\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4816 - accuracy: 0.7079 - val_loss: 1.5148 - val_accuracy: 0.1500\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4893 - accuracy: 0.6976 - val_loss: 0.9875 - val_accuracy: 0.1714\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.5317 - accuracy: 0.6738 - val_loss: 1.1905 - val_accuracy: 0.1714\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4786 - accuracy: 0.7063 - val_loss: 1.1055 - val_accuracy: 0.1429\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4835 - accuracy: 0.7103 - val_loss: 0.9966 - val_accuracy: 0.1714\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.4911 - accuracy: 0.7087 - val_loss: 1.0367 - val_accuracy: 0.2500\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.4943 - accuracy: 0.7103 - val_loss: 0.8958 - val_accuracy: 0.2071\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4844 - accuracy: 0.7024 - val_loss: 0.9145 - val_accuracy: 0.8357\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.5344 - accuracy: 0.6690 - val_loss: 0.9841 - val_accuracy: 0.1500\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4826 - accuracy: 0.7056 - val_loss: 1.3032 - val_accuracy: 0.1429\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4951 - accuracy: 0.6849 - val_loss: 1.1366 - val_accuracy: 0.1214\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4793 - accuracy: 0.6960 - val_loss: 1.2858 - val_accuracy: 0.1214\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4934 - accuracy: 0.6937 - val_loss: 1.0210 - val_accuracy: 0.1500\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4791 - accuracy: 0.7111 - val_loss: 0.9792 - val_accuracy: 0.2000\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4774 - accuracy: 0.7111 - val_loss: 1.0686 - val_accuracy: 0.1429\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4814 - accuracy: 0.6968 - val_loss: 1.2673 - val_accuracy: 0.1429\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4768 - accuracy: 0.7079 - val_loss: 1.4099 - val_accuracy: 0.1357\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.4775 - accuracy: 0.7079 - val_loss: 1.3175 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x388d5d790>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(x_train, y_train,epochs=50, batch_size=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbadb0-c662-4fcd-82db-40c11529419c",
   "metadata": {},
   "source": [
    "Up until about 10 epochs (which represent forward and back passes through the network) the accurracy steadily increases. After 10 epochs, the accuracy begins to plateau and the validation accuracy begins to decrease. This indicates some degree of overfitting to the data. After 10 epochs, the network does not learn much more from the dataset as seen by the steady accuracy.\n",
    "\n",
    "The validation accuracy also begins to decline after about 20 epochs while accuracy increases ever so slightlly which may also indicate overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb91722-70de-4c33-85b4-9eb9964acf89",
   "metadata": {},
   "source": [
    "### ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dd687ff-3eb6-46e5-98de-f876b23ed8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:02:34.453495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-05-07 14:02:34.508036: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 24ms/step\n",
      "Train Accuracy: 0.609\n",
      "19/19 [==============================] - 0s 21ms/step\n",
      "Test Accuracy: 0.482\n"
     ]
    }
   ],
   "source": [
    "train_predictions = lstm_model.predict(x_train)\n",
    "binary_train_predictions = (train_predictions >= 0.5).astype(int)\n",
    "train_accuracy = accuracy_score(y_train, binary_train_predictions)\n",
    "print(f'Train Accuracy: {round(train_accuracy,3)}')\n",
    "\n",
    "test_predictions = lstm_model.predict(x_test)\n",
    "binary_test_predictions =(test_predictions>= 0.5).astype(int)\n",
    "test_accuracy = accuracy_score(y_test, binary_test_predictions)\n",
    "print(f\"Test Accuracy: {round(test_accuracy,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d3a8f3-998c-4888-9b2e-eaebc044ad5a",
   "metadata": {},
   "source": [
    "The train accuracy for LSTM model is 0.609 and the test accuracy is 0.482. After running multiple times, the train accuracy for the LSTM model is roughly in the range of 0.6 to 0.74 and the test accuracy is in the range of 0.46-0.55."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bd683c-5fd2-4652-8686-d9ff8ef19ea6",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Cleaning: https://stackoverflow.com/questions/44494431/how-to-list-files-in-a-directory-in-python\n",
    "\n",
    "https://stackoverflow.com/questions/71131172/replace-matched-susbtring-using-re-sub\n",
    "\n",
    "Binary Cross Entropy: https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy\n",
    "\n",
    "Embedded Layer: https://stackoverflow.com/questions/45649520/explain-with-example-how-embedding-layers-in-keras-works\n",
    "\n",
    "1D CNN: https://stackoverflow.com/questions/73851855/1d-cnn-using-tensorflow-keras-classification-problems\n",
    "\n",
    "LSTM: https://github.com/christianversloot/machine-learning-articles/blob/main/build-an-lstm-model-with-tensorflow-and-keras.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
